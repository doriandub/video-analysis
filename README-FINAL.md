# ğŸ¬ Video Analysis API - Hospup

**La solution la plus simple** pour analyser des vidÃ©os (Instagram, S3, CDN) et gÃ©nÃ©rer des descriptions keywords comme ton systÃ¨me actuel.

## ğŸ“¦ Ce que Ã§a fait

- âœ… TÃ©lÃ©charge une vidÃ©o depuis une URL
- âœ… DÃ©tecte les cuts automatiquement (PySceneDetect)
- âœ… Analyse chaque cut avec IA
- âœ… GÃ©nÃ¨re des **keywords** (comme ton prompt hospitality actuel)
- âœ… Retourne un JSON avec clips + descriptions

## ğŸ”¥ Setup en 3 minutes

```bash
# 1. Va dans le dossier
cd /Users/doriandubord/Desktop/hospup-project/video-analysis-api

# 2. Configure (Ã©dite .env)
CAPTION_BACKEND=openai           # ou moondream2 (gratuit mais moins bon)
OPENAI_API_KEY=sk-proj-...       # ta clÃ© OpenAI
API_KEY=ton-secret-key-ici       # pour sÃ©curiser l'API

# 3. DÃ©marre
docker compose up -d --build

# 4. Test
./TEST.sh
```

## ğŸ“Š Output Format (exactement comme ton systÃ¨me)

```json
{
  "clips": [
    {
      "order": 1,
      "start": 0.0,
      "end": 1.5,
      "duration": 1.5,
      "description": "infinity pool, ocean, sun loungers, palm trees"
    },
    {
      "order": 2,
      "start": 1.5,
      "end": 2.8,
      "duration": 1.3,
      "description": "bedroom, bed, window, balcony, furniture"
    }
  ],
  "texts": []
}
```

## ğŸ¯ Prompt utilisÃ©

**C'est EXACTEMENT le mÃªme prompt que ton `openai_vision_service.py`** (lignes 153-185).

Le prompt demande des **keywords sÃ©parÃ©s par virgules** sans adjectifs, juste des noms concrets :
- âœ… "pool, ocean, sun loungers, palm trees"
- âŒ "beautiful luxury pool with amazing ocean view"

## ğŸš€ Utilisation

### CURL basique

```bash
curl -X POST http://localhost:8190/analyze \
  -H "x-api-key: ton-secret-key" \
  -F "url=https://instagram.com/video.mp4" \
  -F "threshold=25" \
  -F "max_cuts=15"
```

### Avec ta vidÃ©o Instagram

```bash
./TEST.sh
```

### Depuis n8n

```json
{
  "method": "POST",
  "url": "http://localhost:8190/analyze",
  "headers": {
    "x-api-key": "{{ $env.VIDEO_API_KEY }}"
  },
  "bodyParameters": {
    "parameters": [
      {"name": "url", "value": "={{ $json.video_url }}"},
      {"name": "threshold", "value": "25"},
      {"name": "max_cuts", "value": "15"}
    ]
  }
}
```

## âš™ï¸ Configuration

### Backend OpenAI (RecommandÃ©)

```bash
# .env
CAPTION_BACKEND=openai
OPENAI_API_KEY=sk-proj-...
```

**Avantages :**
- âœ… MÃªme qualitÃ© que ton systÃ¨me actuel
- âœ… Utilise ton prompt hospitality exact
- âœ… Rapide (~2-3s par vidÃ©o)
- âœ… Pas de GPU nÃ©cessaire

**CoÃ»t :** ~$0.01 par vidÃ©o (10 cuts)

### Backend Moondream2 (Gratuit)

```bash
# .env
CAPTION_BACKEND=moondream2
```

**Avantages :**
- âœ… Gratuit, aucun coÃ»t
- âœ… Marche offline

**InconvÃ©nients :**
- âŒ QualitÃ© infÃ©rieure Ã  OpenAI
- âŒ Plus lent (5-10s par vidÃ©o)
- âŒ NÃ©cessite ~2GB RAM

## ğŸ“ ParamÃ¨tres

| ParamÃ¨tre | Description | DÃ©faut | RecommandÃ© |
|-----------|-------------|--------|------------|
| `url` | URL vidÃ©o (required) | - | - |
| `threshold` | SensibilitÃ© cuts | 27.0 | 20-30 |
| `max_cuts` | Nombre max de cuts | 30 | 10-20 |

**Threshold :**
- `20-25` : VidÃ©os statiques â†’ plus de cuts
- `25-30` : VidÃ©os dynamiques (Instagram)
- `30-35` : Seulement transitions marquÃ©es

## ğŸ“ Structure

```
video-analysis-api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py          # API FastAPI (300 lignes)
â”‚   â””â”€â”€ config.py        # Configuration + prompt hospitality
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                 # Ta configuration
â”œâ”€â”€ TEST.sh              # Script de test
â”œâ”€â”€ QUICKSTART.md        # Guide dÃ©taillÃ©
â””â”€â”€ README.md            # Documentation complÃ¨te
```

## ğŸ§  Comment Ã§a marche

1. **Download** : TÃ©lÃ©charge la vidÃ©o depuis l'URL
2. **Scene Detection** : PySceneDetect trouve les cuts
3. **Frame Extraction** : Extrait la frame du milieu de chaque cut
4. **IA Captioning** : OpenAI Vision ou Moondream2 gÃ©nÃ¨re les keywords
5. **Return JSON** : Format identique Ã  ton systÃ¨me actuel

## ğŸ”’ SÃ©curitÃ©

- API key obligatoire (header `x-api-key`)
- Timeouts configurables
- Nettoyage automatique des fichiers temp
- Limites sur nombre de cuts

## ğŸ“ˆ Performance

| Backend | Vitesse | RAM | CoÃ»t |
|---------|---------|-----|------|
| OpenAI | 2-5s | 500MB | $0.01/video |
| Moondream2 | 5-10s | 2GB | Gratuit |

## ğŸ”§ Debug

```bash
# Voir les logs
docker compose logs -f api

# Rebuild
docker compose up -d --build

# Stop
docker compose down
```

## ğŸ’¡ Tips

1. **Pour vidÃ©os courtes (<10s)** : `threshold=25`, `max_cuts=8`
2. **Pour vidÃ©os Instagram** : `threshold=25-27`, `max_cuts=10-15`
3. **Pour Ã©conomiser** : Utilise moondream2 backend
4. **Pour qualitÃ© max** : Utilise openai backend

## ğŸ‰ Ready to Go!

L'API est prÃªte Ã  Ãªtre intÃ©grÃ©e dans ton n8n workflow. Elle utilise **exactement le mÃªme prompt** que ton systÃ¨me d'upload d'assets.

## ğŸ“š Documentation

- **QUICKSTART.md** : Guide de dÃ©marrage dÃ©taillÃ©
- **README.md** : Documentation API complÃ¨te
- **TEST.sh** : Script de test avec ta vidÃ©o Instagram

## â“ Questions ?

1. **"Pourquoi OpenAI et pas BLIP comme avant ?"**
   - Tu utilises dÃ©jÃ  OpenAI Vision dans `openai_vision_service.py`
   - J'ai copiÃ© ton prompt exact

2. **"C'est quoi la diffÃ©rence avec mon systÃ¨me actuel ?"**
   - Ton systÃ¨me : analyse 1 vidÃ©o entiÃ¨re â†’ 1 description
   - Cette API : dÃ©coupe en cuts â†’ 1 description par cut
   - **MÃªme prompt, mÃªme qualitÃ©**

3. **"Ã‡a coÃ»te combien ?"**
   - OpenAI : ~$0.01 par vidÃ©o (10 cuts)
   - Moondream2 : Gratuit

4. **"C'est compatible avec mon workflow n8n ?"**
   - Oui ! Simple HTTP POST request
   - Voir exemples dans QUICKSTART.md
